{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "import bs4 as bs\n",
    "import json\n",
    "import traceback\n",
    "import re\n",
    "import numpy as np\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import glob, os\n",
    "import asyncio\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. BBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_to_visit = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link(url):\n",
    "    home_bbc = rq.get(url)\n",
    "    soup = bs.BeautifulSoup(home_bbc.text, 'html.parser')\n",
    "    for a in soup.find_all('a', href=True):\n",
    "        if a.text:\n",
    "            link = a[\"href\"]\n",
    "            if link.startswith(\"/swahili/habari-\") or link.startswith(\"/swahili/michezo-\"):\n",
    "                if link not in list(links_to_visit.keys()):\n",
    "                    links_to_visit[link] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_link(\"https://www.bbc.com/swahili\")\n",
    "get_link(\"https://www.bbc.com/swahili/michezo\")\n",
    "len(links_to_visit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in list(links_to_visit.keys()):\n",
    "    link_url = \"https://www.bbc.com/\" + link\n",
    "    if links_to_visit[link] == False:\n",
    "        get_link(link_url)\n",
    "        links_to_visit[link] = True\n",
    "        \n",
    "        no_link = all(value == True for value in list(links_to_visit.values()))\n",
    "        if no_link:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(links_to_visit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_visit_rfi = {}\n",
    "load_more = \"btn-load-more alt more-loader\"\n",
    "\n",
    "seed = [\"http://sw.rfi.fr/ulaya/all/\", \n",
    "        \"http://sw.rfi.fr/amerika/all/\", \n",
    "        \"http://sw.rfi.fr/mashariki-ya-kati/all/\",\n",
    "        \"http://sw.rfi.fr/asia/all/\",\n",
    "        \"http://sw.rfi.fr/afrika/all/\",\n",
    "        \"http://sw.rfi.fr/eac/all/\",\n",
    "        \"http://sw.rfi.fr/siasa-uchumi/all/\",\n",
    "        \"http://sw.rfi.fr/afya-mazingira/all/\",\n",
    "        \"http://sw.rfi.fr/utamaduni/all/\",\n",
    "        \"http://sw.rfi.fr/michezo/all/\"]\n",
    "\n",
    "driver = webdriver.Chrome(executable_path=\"/home/aims/Downloads/chromedriver\")\n",
    "driver.get(\"http://sw.rfi.fr/afrika/all/\")\n",
    "loadmore = driver.find_element_by_class_name(\"cookie-bar_hide\")\n",
    "loadmore.click()\n",
    "while True:\n",
    "    try:\n",
    "        time.sleep(1)\n",
    "        loadmore = WebDriverWait(driver, 120).until(EC.visibility_of_element_located((By.CLASS_NAME, \"btn-load-more\")))\n",
    "        loadmore.click()\n",
    "        time.sleep(1)\n",
    "    except Exception:\n",
    "        print(\"Reached bottom of page\")\n",
    "        traceback.print_exc()\n",
    "        break\n",
    "\n",
    "soup_rfi = bs.BeautifulSoup(driver.page_source,'html.parser')\n",
    "# home_rfi.text\n",
    "# soup_rfi = bs.BeautifulSoup(home_rfi.text, 'html.parser')\n",
    "news_links = soup_rfi.find_all('a', href=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data, filename=\"final.txt\"):\n",
    "    with open(filename, 'w') as f:\n",
    "        for item in data:\n",
    "            f.write(\"%s\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_final = []\n",
    "\n",
    "for a in news_links:\n",
    "    if a.text:\n",
    "        link = a[\"href\"]\n",
    "        matching = re.match(r'^\\/michezo\\/\\d+\\w+', link)\n",
    "        if matching:\n",
    "            new_link = 'http://sw.rfi.fr'+link\n",
    "            news_final.append(new_link)\n",
    "\n",
    "save_data(news_final, 'michezo.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"./\")\n",
    "final_data = []\n",
    "for file in glob.glob(\"*.txt\"):\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            if line not in final_data:\n",
    "                final_data.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19593"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_data(final_data, 'news_final.txt')\n",
    "len(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []\n",
    "def get_urls():\n",
    "    with open(\"news_final.txt\") as f:\n",
    "        for line in f:\n",
    "            urls.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_urls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = []\n",
    "\n",
    "def do_req(url):\n",
    "    return rq.get(url, headers=headers)\n",
    "\n",
    "async def main():\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=100) as executor:\n",
    "        loop = asyncio.get_event_loop()\n",
    "        futures = [\n",
    "            loop.run_in_executor(\n",
    "                executor, \n",
    "                do_req,\n",
    "                url\n",
    "            )\n",
    "            for url in urls\n",
    "        ]\n",
    "        i = 0\n",
    "        for response in await asyncio.gather(*futures):\n",
    "            page_soup = bs.BeautifulSoup(response.text, 'html.parser')\n",
    "            news_title = page_soup.select_one('article h1')\n",
    "            news_title = news_title.text if news_title else ''\n",
    "            news_body = page_soup.select_one('article div[itemprop=\"articleBody\"]')\n",
    "            \n",
    "            # image \n",
    "            img_caption = page_soup.select_one('article div.media img[itemprop=\"image\"]')\n",
    "            img_caption_desc = page_soup.select_one('article div.media small')\n",
    "            \n",
    "            if img_caption['src'] and img_caption_desc.text:\n",
    "                i = i + 1 \n",
    "            \n",
    "            news_body = news_body.text if news_body else ''\n",
    "            final_data.append({'title' : news_title, 'content' : news_body})\n",
    "        print(\"Total number of caption {}\".format(i))\n",
    "\n",
    "\n",
    "loop = asyncio.get_event_loop()\n",
    "loop.run_until_complete(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = []\n",
    "for item in final_data:\n",
    "    if item['content'] != '':\n",
    "        full.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_full.json', 'w') as fout:\n",
    "    json.dump(full, fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 3. VOA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 3.1 Swahili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "home_voa_swahili = rq.get(\"https://www.voaswahili.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_voa_swahili"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 3.2 Lingala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# home_voa_lingala = rq.get(\"https://www.voalingala.com\") / https://www.voalingala.com/z/5744\n",
    "\n",
    "driver = webdriver.Chrome(executable_path=\"/home/aims/Downloads/chromedriver\")\n",
    "driver.get(\"https://www.voalingala.com/z/5744\")\n",
    "while True:\n",
    "    try:\n",
    "        time.sleep(1)\n",
    "        loadmore = WebDriverWait(driver, 120).until(EC.visibility_of_element_located((By.CLASS_NAME, \"link-showMore\")))\n",
    "        loadmore.click()\n",
    "        time.sleep(1)\n",
    "    except Exception:\n",
    "        print(\"Reached bottom of page\")\n",
    "        traceback.print_exc()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2062"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_page = bs.BeautifulSoup(driver.page_source,'html.parser')\n",
    "news_links = home_page.find_all('a', href=True)\n",
    "len(news_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.json\", \"r\") as read_file:\n",
    "    data = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sw_final.txt', 'w') as file:\n",
    "    for item in data:\n",
    "        join_title_description = item['title'] + '\\n\\n' + item['content'] + '\\n\\n'\n",
    "        file.write(join_title_description)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
